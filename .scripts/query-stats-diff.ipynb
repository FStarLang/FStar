{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize these variables to match your environment\n",
    "dump_file_v1 = (\"../dump1\", \"4.13.3\")\n",
    "dump_file_v2 = (\"../dump2\", \"4.8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version1 = dump_file_v1[1]\n",
    "version2 = dump_file_v2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse lines of a file like this:\n",
    "# (FStar.Seq.Properties.fsti(230,0-232,71))       Query-stats (FStar.Seq.Properties.lemma_ordering_hi_cons, 1)    succeeded in 10 milliseconds with fuel 2 and ifuel 1 and rlimit 5\n",
    "# and produce a dictionary with the following structure:\n",
    "#  { \"FStar.Seq.Properties.lemma_ordering_hi_cons, 1\" : { status:\"succeeded\" , \"time\" : 10, \"fuel\" : 2, \"ifuel\" : 1, \"rlimit\" : 5 } }\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "\n",
    "query_stats_re = re.compile(r'Query-stats \\(([^,]+, \\d+)\\)\\s+(succeeded|failed)( {[^}]+})?( \\(with hint\\))? in (\\d+) milliseconds with fuel (\\d+) and ifuel (\\d+) and rlimit (\\d+)')\n",
    "splitting_query_stats = re.compile(r'Query-stats splitting query')\n",
    "\n",
    "def parse_line(line):\n",
    "    m = query_stats_re.search(line)\n",
    "    if m:\n",
    "        return { m.group(1) : { \"status\" : m.group(2), \"reason\":m.group(3), \"with_hint\":m.group(4), \"time\" : int(m.group(5)), \"fuel\" : int(m.group(6)), \"ifuel\" : int(m.group(7)), \"rlimit\" : int(m.group(8)) } }\n",
    "    else:\n",
    "        m = splitting_query_stats.search(line)\n",
    "        if m:\n",
    "            return None\n",
    "        else:\n",
    "            if \"Query-stats\" in line:\n",
    "                if \"{\\\"contents\\\":\" in line:\n",
    "                    return None \n",
    "                print(\"Failed to parse line: \" + line)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_line=parse_line(\"(FStar.Seq.Properties.fsti(230,0-232,71))        Query-stats (FStar.Seq.Properties.lemma_ordering_hi_cons, 1)    succeeded (with hint) in 10 milliseconds with fuel 2 and ifuel 1 and rlimit 5\")\n",
    "if test_line:\n",
    "    print(\"Parsed line: \", test_line)\n",
    "    json.dumps(test_line)\n",
    "else:\n",
    "    print(\"Failed to parse line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_file(file):\n",
    "    d = {}\n",
    "    print(\"opening file\", file)\n",
    "    with open(file, encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            # print(line)\n",
    "            r = parse_line(line)\n",
    "            if r:\n",
    "                d.update(r)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3_v1 = parse_file(dump_file_v1[0])\n",
    "print(\"Parsed\", len(z3_v1), \"entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3_v2 = parse_file(dump_file_v2[0])\n",
    "print(\"Parsed\", len(z3_v2), \"entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find entries in z3_v2 that are not in z3_v1\n",
    "for k in z3_v2.keys():\n",
    "    if k not in z3_v1:\n",
    "        print(f\"Missing entry in {version1}: {k}\")\n",
    "\n",
    "# find entries in z3_v1 that are not in z3_v2\n",
    "for k in z3_v1.keys():\n",
    "    if k not in z3_v2:\n",
    "        print(f\"Missing entry in {version2}: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every entry in both dictionaries, create a new dictionary with the same key, the time fields of both dictionaries, and the difference between the times\n",
    "diffs = {}\n",
    "for k in z3_v1.keys():\n",
    "    if k in z3_v2.keys():\n",
    "        diffs[k] = { version1 : z3_v1[k][\"time\"], version2 : z3_v2[k][\"time\"], \"diff\" : z3_v2[k][\"time\"] - z3_v1[k][\"time\"] }\n",
    "\n",
    "print(f\"Found {len(diffs)} entries with both {version1} and {version2} times\")\n",
    "json.dumps(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the entries by the difference in time\n",
    "sorted_diffs = sorted(diffs.items(), key=lambda x: x[1][\"diff\"], reverse=True)\n",
    "\n",
    "print(sorted_diffs)\n",
    "#print the top 10\n",
    "print(f\"Entries with the greatest speedups in {version1}:\")\n",
    "for i in range(10):\n",
    "    print(sorted_diffs[i])\n",
    "\n",
    "print(f\"Entries with the greatest slowdowns in {version1}\")\n",
    "# print the bottom 10\n",
    "for i in range(10):\n",
    "    print(sorted_diffs[-(i + 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot with 485 times on x axis and 413 times on y axis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# remove outliers\n",
    "diffs = {k:v for k,v in sorted_diffs if abs(v[\"diff\"]) < 10000}\n",
    "\n",
    "x = [v[version2] for v in diffs.values()]\n",
    "y = [v[version1] for v in diffs.values()]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(version2)\n",
    "plt.ylabel(version1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression of v1 times on v2 times\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print(\"slope:\", slope, \"intercept:\", intercept, \"r_value:\", r_value, \"p_value:\", p_value, \"std_err:\", std_err)\n",
    "plt.plot(x, [slope * v + intercept for v in x])\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(version2)\n",
    "plt.ylabel(version1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all outliers\n",
    "for k,v in sorted_diffs:\n",
    "    if abs(v[\"diff\"]) > 10000:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all sorted diffs\n",
    "for k,v in diffs.items():\n",
    "    print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
